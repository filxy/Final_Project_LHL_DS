# -*- coding: utf-8 -*-
"""DFD_streamlit-app

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YPJowCu1G0CD9bhg9-N1KAY5saqW0vWw
"""

#!pip install -q streamlit
#!pip install ipykernel==4.10
#!pip install ipython==5.5.0
#!pip install pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile DFD_streamlit-app.py
# 
# import cv2
# import ipykernel
# import pyngrok
# import time
# import numpy as np
# import streamlit as st
# import tensorflow as tf
# from tensorflow.keras.preprocessing import image
# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input as mobilenet_v2_preprocess_input
# 
# #model = tf.keras.models.load_model("")
# map_dict ={
#     0:'Deep Fake'
#     1:'Real'
# }
# 
# camera = st.container()
# upload = st.container()
# bar = st.container()
# 
# st.title('Deep Fake Detector')
# 
# st.write('Detect using Real-time Web cam image:')
# 
# with st.container():
#    img_file_buffer = st.camera_input("Take a picture")
# 
# if img_file_buffer is not None:
#     # To read image file buffer as bytes:
#     bytes_data = img_file_buffer.getvalue()
#     # Check the type of bytes_data:
#     # Should output: <class 'bytes'>
#     st.write(type(bytes_data))
# 
# if uploaded_file is not None:
#     # Convert the file to an opencv image.
#     file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
#     opencv_image = cv2.imdecode(file_bytes, 1)
#     opencv_image = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)
#     resized = cv2.resize(opencv_image,(224,224))
#     # Now do something with the image! For example, let's display it:
#     st.image(opencv_image, channels="RGB")
# 
#     resized = mobilenet_v2_preprocess_input(resized)
#     img_reshape = resized[np.newaxis,...]
# 
#     
# st.write('Detect by uploading image or video')
# 
# with st.container():
#   uploaded_files = st.file_uploader("Choose a image or video file", accept_multiple_files=True)
# for uploaded_file in uploaded_files:
#      bytes_data = uploaded_file.read()
#      st.write("filename:", uploaded_file.name)
#      st.write(bytes_data)
# 
# if uploaded_file is not None:
#     # Convert the file to an opencv image.
#     file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
#     opencv_image = cv2.imdecode(file_bytes, 1)
#     opencv_image = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)
#     resized = cv2.resize(opencv_image,(224,224))
#     # Now do something with the image! For example, let's display it:
#     st.image(opencv_image, channels="RGB")
# 
#     resized = mobilenet_v2_preprocess_input(resized)
#     img_reshape = resized[np.newaxis,...]
# 
# 
# 
# 
# with st.container():
#   my_bar = st.progress(0)
# 
# for percent_complete in range(100):
#      time.sleep(0.1)
#      my_bar.progress(percent_complete + 1)
# 
#      st.success('Upload Successful!')
#      Genrate_pred = st.button("Generate Prediction")    
#      if Genrate_pred:
#        prediction = model.predict(img_reshape).argmax()
#        st.title("Predicted Label for the image is {}".format(map_dict[prediction]))
# 
#      
#

#!ngrok authtoken 255CfLKyQv7ggmtfYr6jleoiA0z_3mxsRxWi9XvTatfcWxPdf

#from pyngrok import ngrok
#!ps -Al | grep streamlit

#!streamlit run DFD_streamlit-app.py --server.port=80

!streamlit run DFD_streamlit-app.py
#!streamlit run /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py

#!pgrep streamlit

#publ_url = ngrok.connect(port='8501')

#publ_url